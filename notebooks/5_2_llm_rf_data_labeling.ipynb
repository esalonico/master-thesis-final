{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f393a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4240059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for storing LLM responses\n",
    "responses_dir = Path(\"../.llm_responses\")\n",
    "responses_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# initialize OpenAI client\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6ffd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_file_exists(paper_id, question_id, responses_dir):\n",
    "    \"\"\"Check if response file already exists for given paper and question\"\"\"\n",
    "    filename = f\"{paper_id}_{question_id}.json\"\n",
    "    filepath = responses_dir / filename\n",
    "    return filepath.exists()\n",
    "\n",
    "\n",
    "def save_response(paper_id, question_id, prompt, response, responses_dir):\n",
    "    \"\"\"Save LLM response to JSON file\"\"\"\n",
    "    filename = f\"{paper_id}_{question_id}.json\"\n",
    "    filepath = responses_dir / filename\n",
    "\n",
    "    data = {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"question_id\": question_id,\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response.choices[0].message.content,\n",
    "        \"model\": response.model,\n",
    "        \"input_tokens\": response.usage.prompt_tokens,\n",
    "        \"output_tokens\": response.usage.completion_tokens,\n",
    "    }\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def call_llm_with_caching(paper_title, paper_abstract, question_text, paper_id, question_id):\n",
    "    \"\"\"\n",
    "    Call OpenAI API with prompt caching.\n",
    "    Structure:\n",
    "    - System message (cached): Instructions\n",
    "    - User message (cached): Title + Abstract\n",
    "    - User message (not cached): Specific question\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a systematic review screening assistant. Your task is to determine if a paper meets specific inclusion or exclusion criteria based on its title and abstract. You must answer with ONLY one word: YES, NO, or UNSURE (only if you are really uncertain). Do not provide any explanation or additional text.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Title: {paper_title}\\n\\nAbstract: {paper_abstract}\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Task: according to the paper's title and abstract, answer the following question. Only answer with YES, NO or UNSURE (just if you are really unsure). Nothing else.\\n\\nQuestion: {question_text}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(model=OPENAI_MODEL, messages=messages)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing paper {paper_id}, question {question_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16560480",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffcf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "include_exclude",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "notes",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6f756b92-3002-4dec-a22a-16310691c59b",
       "rows": [
        [
         "0",
         "I1",
         "Does the paper describe a randomized controlled trial (RCT), controlled clinical trial (CCT), or any trial with prospective assignment of participants?",
         "study_design",
         "include",
         "This inclusion criterion is like the \"I3\"; however, \"I3\" was to look for words linked to RCT, while this one is more conceptual. In addition, here we also ask for \"trial with prospective assignment of participants,\" because the selection AI missed studies where interventions were mentioned but not the study design. The latter part of this question asks for that. On the other hand, given the fact that this generates noise because it also selects studies with interventions but without randomization (which are not of interest), we could consider optimizing it and splitting it accordingly."
        ],
        [
         "1",
         "I2",
         "Does the paper include or reference a trial registry identifier (e.g., NCT, ISRCTN, EudraCT, or similar)?",
         "study_design",
         "include",
         "This is a repetition of \"I1\"; we can optimize"
        ],
        [
         "2",
         "I3",
         "Is this an interventional study where participants receive a defined treatment, program, or intervention (as opposed to purely observational or qualitative research)?",
         "study_design",
         "include",
         "This tends to narrow the scope of the \"trial with prospective assignment of participants\" of \"I4\"; we can consider an optimization."
        ],
        [
         "3",
         "I4",
         "Does the study include participants with schizophrenia or schizophrenia spectrum disorders?",
         "population",
         "include",
         "This is like \"I4\", in the sense that this is used for conceptual querying to the model while the \"I2\" looks for terms. This is a bit broader and it is like a safety net for the other. We could plan an optimization."
        ],
        [
         "4",
         "I5",
         "Does the study include participants with non-affective psychotic disorders, such as first-episode psychosis, brief psychotic disorder, or delusional disorder?",
         "population",
         "include",
         "OK, this goes into detail on the diagnoses/symptoms typically in schizophrenia patients we need anyway."
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>include_exclude</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>Does the paper describe a randomized controlle...</td>\n",
       "      <td>study_design</td>\n",
       "      <td>include</td>\n",
       "      <td>This inclusion criterion is like the \"I3\"; how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I2</td>\n",
       "      <td>Does the paper include or reference a trial re...</td>\n",
       "      <td>study_design</td>\n",
       "      <td>include</td>\n",
       "      <td>This is a repetition of \"I1\"; we can optimize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I3</td>\n",
       "      <td>Is this an interventional study where particip...</td>\n",
       "      <td>study_design</td>\n",
       "      <td>include</td>\n",
       "      <td>This tends to narrow the scope of the \"trial w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I4</td>\n",
       "      <td>Does the study include participants with schiz...</td>\n",
       "      <td>population</td>\n",
       "      <td>include</td>\n",
       "      <td>This is like \"I4\", in the sense that this is u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I5</td>\n",
       "      <td>Does the study include participants with non-a...</td>\n",
       "      <td>population</td>\n",
       "      <td>include</td>\n",
       "      <td>OK, this goes into detail on the diagnoses/sym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question      category  \\\n",
       "0  I1  Does the paper describe a randomized controlle...  study_design   \n",
       "1  I2  Does the paper include or reference a trial re...  study_design   \n",
       "2  I3  Is this an interventional study where particip...  study_design   \n",
       "3  I4  Does the study include participants with schiz...    population   \n",
       "4  I5  Does the study include participants with non-a...    population   \n",
       "\n",
       "  include_exclude                                              notes  \n",
       "0         include  This inclusion criterion is like the \"I3\"; how...  \n",
       "1         include      This is a repetition of \"I1\"; we can optimize  \n",
       "2         include  This tends to narrow the scope of the \"trial w...  \n",
       "3         include  This is like \"I4\", in the sense that this is u...  \n",
       "4         include  OK, this goes into detail on the diagnoses/sym...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_questions = pd.read_csv(\"../data/5_llm_questions.csv\")\n",
    "llm_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806f11cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MK_IN",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "MK_IN_source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ti_ab",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "FH_Err",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "DC_Notes",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "journal_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Publication_Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DOI",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Volume",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Pages",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Reviewed_Item",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DB",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DP",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "ae8bdcf2-ff43-4a6f-8863-52c8efb64bb2",
       "rows": [
        [
         "0",
         "0",
         "False",
         "auto",
         "False",
         "False",
         null,
         null,
         "\"Cognitive Assessment in Psychiatric Patients Before and After Electroconvulsive Therapy in A Teritiary Care Teaching Hospital\"",
         "Background: Electroconvulsive treatment (ECT) is a procedure that creates a generalized cerebral seizure by using an electric current and electrodes inserted in the cranial vault under anesthesia. Electrical charges are delivered through these electrodes to cause seizures. For the past sixty years, it has been employed as a therapeutic therapy for the treatment of psychiatric disorder. ECT has been reported to be useful for pharmacologically resistant mental illnesses<sup>1</sup>, but at the immediate cost of a loss in emotional processing speed.<sup>2</sup> Objectives: 1. To study the cognitive functions before, immediately after the first electroconvulsive therapy, and at the end of one week of last electroconvulsive therapy. 2. To compare the cognitive functions before and after electroconvulsive therapy administration. 3. To correlate the cognitive functions and illness variable with electroconvulsive therapy. Material(s) and Method(s): Study Design: Hospital based prospective observational study. Study area: Manasa Psychiatry Hospital, Secunderbad, Telangana. Study Period: August 2022 - August 2023. Study population: Patients suffering from psychiatric illness and planned for electroconvulsive therapy as recommended treatment option. Sample size: Study consisted a total of 50 subjects. Sampling Technique: Simple Random sampling. Study tools and Data collection procedure: TOOLS USED: 1) Semi-structured Proforma 2) PGI memory test 3) Digit symbol substitution test 4) Color Trail test-1 5) Color Trail test-2 6) Controlled Oral Word Association Test (COWA) 7) Addenbrooke's Cognitive rating scale (ACE-R). After obtaining consent, patients who meet the exclusion and inclusion criteria were enrolled in the study design. Patients who took up for the study were able to understand the nature and purpose of the study. Uncooperative patients and patients with acute psychosis were ruled out from the study. Semi-structured proforma was administered for the patients taken up for the study. Socio-demographic profile as per the proforma was collected. Complete general physical examination and also detailed neurological evaluation were done before the study. All the subjects underwent cognitive assessment which lasted around 90 minutes. All the tests were carried out in a fixed order according to standardized administration procedures in a quiet room. Result(s): the mean COWA scores at baseline showed significantly higher scores as compared to 24 hrs at P<0.001. These results infer that the mean COWA scores show a difference between first ECT and 1-week post ECT which was highly significant statistically and further the difference between baseline and 1-week post-ECT was highly significant as it shows a significant increase in the scores at a 1-week time interval. P<0.001. Conclusion(s): From our study it can be concluded that, the ECT course causes rapid cognitive changes, both in the form of impairment as well as improvement. ECT treatment has effects on memory as well as other non-memory cognitive functions. ECT has acute effects on cognitive functions which are evident by changes in the cognitive profile of participating patients seen immediately after the first ECT. Copyright © 2023 Healthcare Bulletin. All rights reserved.",
         "European Journal of Cardiovascular Medicine",
         "Sharma, V.; Gade, V.; Rajeev, A.; Saudam, M.; Neerugatti, B.; Reddy, V. S.",
         "2023",
         null,
         "13(4)",
         "924-935",
         null,
         "Embase",
         "Ovid Technologies"
        ],
        [
         "1",
         "1",
         "True",
         "auto",
         "True",
         "True",
         null,
         null,
         "\"Comparison of the impact of peer education and familiarization tour on the level of fear, knowledge, and attitude towards electroconvulsive therapy in patients with psychiatric disorders.\"",
         "Inclusion criteria: \"All patients with psychiatric disorders hospitalized in 505 AJA Hospital for whom the doctor has prescribed electroconvulsive therapy for the first time.\" \"Ability to read and write, proficiency in the Persian language.\" \"Absence of physical illness leading to cognitive disorders such as head trauma, dementia, intellectual disability, and absence of physical illness or impairments such as visual, auditory, or speech weakness.\" Exclusion criteria: \"Individuals with cognitive disorders.\" \"Individuals who do not wish to participate in the study.\" \"Individuals under 18 years and over 60 years.\" \"Individuals who have previously undergone electroconvulsive therapy.\" \"Individuals for whom electroconvulsive therapy has not been approved by the doctor.\" <Condition>\"Bipolar Disorders (BID), Major Depressive Disorder (MDD), Schizophrenia, Catatonia, Substance-Induced Psychosis, and Other Psychiatric Disorders.. </Condition> Intervention 1: \"Intervention Group: First.\"Intervention: The intervention involves peer education within the peer education group. The educational program in the peer education group includes at least one two-hour session for the peer, which will be conducted by the researcher on the morning of the day before electroconvulsive therapy (ECT) in a face-to-face manner in the counseling room of the ward. This session is for the peer who has had a successful experience with ECT and voluntarily enters the study. The sessions may be conducted individually or in groups. The number of sessions at this stage will vary between one to two sessions, depending on the needs of the patients.The educational content includes: introduction, acquaintance, educational goals and trust-building, understanding the disease, symptoms, complications, types of treatment methods, introduction to ECT and its indications, introduction and role of the treatment team, introduction to equipment and medications, pre-, during-, and post-ECT preparations, complications and methods to reduce and manage them, correcting misconceptions and negative beliefs, sharing personal experiences, self-care education, and training on effective communication with patients for the peer (Appendix 5).At the end of the training, the eligibility of the peer will be evaluated and confirmed by the researcher through questions and answers. The peer will then provide the training with an emphasis on sharing their experiences with the patients on the same day, either at the patient’s bedside or in the counseling room of the ward. During this period, the researcher will be present in the ward to supervise and support the peer. Intervention 2: Intervention group: Second ? In the familiarization tour group, the training will take pl Level of fear. Timepoint: \"Before the intervention and immediately after the intervention.\". Method of measurement: \"Ranjbar and colleagues' Fear Questionnaire.\". \"Level of Knowledge and Attitude of Individuals.\". Timepoint: \"Before and immediately after the intervention.\". Method of measurement: \"Hoffmans Knowledge and Attitude Questionnaire.\".",
         "https://irct.behdasht.gov.ir/trial/80261",
         "IRCT20241108063635N1",
         "2024",
         null,
         null,
         null,
         null,
         "IRCT",
         null
        ],
        [
         "2",
         "2",
         "True",
         "auto",
         "True",
         "True",
         null,
         null,
         "\"Comparison of two Anaesthesia Drugs Thiopental and Etomidate during Electroconvulsive Therapy. (ECT) ?",
         "Inclusion criteria: ASA 1 and 2 patients scheduled to under go ECT for various indications . &lt;br/ &gt; Hemodynamically stable at the time of ECT Exclusion criteria: Patients refused to participate in the study &lt;br/ &gt; Allergy to trial drugs &lt;br/ &gt; <Condition>Health Condition 1: F23- Brief psychotic disorder Health Condition 2: F200- Paranoid schizophrenia Health Condition 3: F250- Schizoaffective disorder, bipolartype </Condition> Intervention1: Etomidate in modified electroconvulsive Therapy: Etomidate 0.2mg /kg[0.2%]injected intravenously and the patient is monitored for 60 minutes after the procedure Intervention2: Thiopental during modified electroconvulsive therapy: Induction by Thiopental during modified electroconvulsive therapy Intervention3: Thiopental during modified electroconvulsive therapy: Thiopental sodium 4mg/kg [2.5%]injected intravenously monitored for 60 minutes after the procedure Intervention4: Etomidate in modified electroconvulsive Therapy: Induction by etomidate in modified Electroconvulsive Therapy Intervention5: Thiopental during modified electroconvulsive therapy: Induction by Thiopental during modified electroconvulsive therapy Intervention6: Etomidate as induction agent in modified electroconvulsive therapy: Etomidate 0.2mg /kg[0.2%]injected intravenously over 30 to 60 seconds as induction agent in MECT Control Intervention1: Thiopental during modified electroconvulsive therapy: Thiopental sodium 4mg/kg [2.5%]injected intravenously over 30 to 60 seconds as induction agent in modified electroconvulsive therapy To compare the effect of Thiopental and Etomidate on hemodynamic changes during ECTTimepoint: 18 months To compare the effect of Thiopental and Etomidate with respect to duration of clinical seizure &lt;br/ &gt; To compare the recovery time between Thiopental and Etomidate &lt;br/ &gt; To compare adverse drug reactions between Thiopental and Etomidate &lt;br/ &gt; Assessment of the cognitive function before and after ECTTimepoint: 18 months",
         "http://www.ctri.nic.in/Clinicaltrials/pmaindet2.php?trialid=96412",
         "CTRI/2024/09/073405",
         "2024",
         null,
         null,
         null,
         null,
         "CTRI",
         null
        ],
        [
         "3",
         "3",
         "True",
         "auto",
         "False",
         "False",
         null,
         null,
         "\"Efficacy of intensive bilateral Temporo-Parietal Continuous theta-burst Stimulation for Auditory VErbal hallucinations (TPC-SAVE) in schizophrenia: A randomized sham-controlled trial\"",
         "Transcranial magnetic stimulation (TMS) is a non-invasive tool that moderates specific brain regions to ameliorate auditory verbal hallucinations (AVH) in schizophrenia. Citing the critical involvement of temporoparietal cortex (TPC) in AVH, our study aimed to evaluate the effect of continuous theta burst stimulation (cTBS) targeting bilateral TPC in schizophrenia subjects with AVH, on a randomized rater blinded placebo control trial. 59 patients were randomly allocated to active and sham groups. They received 20 cTBS sessions (2 per day: first right TPC, then left TPC) 5 days a week for 2 weeks. PANSS (Positive and Negative Syndrome Scale), AVHRS (Auditory vocal hallucination rating scale), PSYRAT-AH (Psychiatric symptoms rating scale- Auditory hallucinations scale), CDSS (Calgary depression scale for schizophrenia), SCoRS (Schizophrenia cognition rating scale) and CGI-S (Clinical global impression-severity) were rated at baseline, immediately post 20th session and 2 weeks post-TBS. 50 patients (25-active, 25-sham) completed the study. Conducting an intention to treat analysis, we found a significant group*time effect for PANSS, AVHRS, PSYRAT-AH, CDSS, SCoRS, CGI-S but when controlled for confounding variables and multiple comparisons, only PANSS-PS (F = 26.617, p < 0.001), PANSS-TOTAL (F = 23.671, p < 0.001), AVHRS (F = 17.779, p < 0.001), PSYRAT-AH (F = 11.385, p < 0.001) and CGI-S (F = 28.462, p < 0.001) retained significance. We conclude that cTBS over TPC is safe and has efficacy in treating AVH in schizophrenia. Limited sample size and lack of integrity assessment for blinding in the study participants are major limitations of the study. (PsycInfo Database Record (c) 2024 APA, all rights reserved)",
         "Asian Journal of Psychiatry",
         "Tyagi, Priya; Dhyani, Mohan; Khattri, Sumit; Tejan, Veena; Tikka, Sai Krishna; Garg, Shobit",
         "2022",
         null,
         "74",
         "1-7",
         null,
         "APA PsycInfo",
         "Ovid Technologies"
        ],
        [
         "4",
         "4",
         "False",
         "auto",
         "False",
         "False",
         null,
         null,
         "\"Empowering Hope: Non-Pharmacological Interventions for Borderline Personality Disorder (BPD) Communities\": Scoping Review",
         "<b>Aim</b>: Borderline personality disorder (BPD) is defined by impulsive behaviour and instability in interpersonal relationships, self-image, mood, and emotions. BPD can be prevented and treated using a mix of medication and psychotherapy. Non-pharmacological interventions are essential for maintaining stable interpersonal interactions in individuals with BPD. <b>Goal</b>: The literature review tries to identify different methods of non-pharmacological management. Psychotherapy, particularly tailored to aid in the recovery from emotional disorders in individuals with BPD. The methodology employed is a scoping review that integrates papers from Semantic Scholars, Pubmed, and CINAHL databases. The keyword utilised is PICO. <b>Outcomes</b>: Four pieces of literature aligned with the research goals based on the literature review results. Three articles discuss therapies that focus on cognitive processes, such as mindfulness therapy, schema therapy, Dialectical Behavioural Therapy (DBT), and therapy groups that incorporate supplementing with Omega-3. <b>Conclusion</b>: Non-pharmacological therapies for patients with Borderline Personality Disorder (BPD) can enhance good psychosocial outcomes, dialectical effects, and decrease emotional instability.",
         "Journal of multidisciplinary healthcare",
         "Maulana, I.; Suryani, S.; Sriati, A.; Yosep, I.; Amira, I.; Hendrawati",
         "2024",
         null,
         "17",
         "4603-4609",
         null,
         "MEDLINE",
         "Ovid Technologies"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MK_IN</th>\n",
       "      <th>MK_IN_source</th>\n",
       "      <th>label</th>\n",
       "      <th>ti_ab</th>\n",
       "      <th>FH_Err</th>\n",
       "      <th>DC_Notes</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>Publication_Year</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Reviewed_Item</th>\n",
       "      <th>DB</th>\n",
       "      <th>DP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Cognitive Assessment in Psychiatric Patients ...</td>\n",
       "      <td>Background: Electroconvulsive treatment (ECT) ...</td>\n",
       "      <td>European Journal of Cardiovascular Medicine</td>\n",
       "      <td>Sharma, V.; Gade, V.; Rajeev, A.; Saudam, M.; ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13(4)</td>\n",
       "      <td>924-935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Embase</td>\n",
       "      <td>Ovid Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Comparison of the impact of peer education an...</td>\n",
       "      <td>Inclusion criteria: \"All patients with psychia...</td>\n",
       "      <td>https://irct.behdasht.gov.ir/trial/80261</td>\n",
       "      <td>IRCT20241108063635N1</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IRCT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Comparison of two Anaesthesia Drugs Thiopenta...</td>\n",
       "      <td>Inclusion criteria: ASA 1 and 2 patients sched...</td>\n",
       "      <td>http://www.ctri.nic.in/Clinicaltrials/pmaindet...</td>\n",
       "      <td>CTRI/2024/09/073405</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTRI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Efficacy of intensive bilateral Temporo-Parie...</td>\n",
       "      <td>Transcranial magnetic stimulation (TMS) is a n...</td>\n",
       "      <td>Asian Journal of Psychiatry</td>\n",
       "      <td>Tyagi, Priya; Dhyani, Mohan; Khattri, Sumit; T...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>1-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APA PsycInfo</td>\n",
       "      <td>Ovid Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Empowering Hope: Non-Pharmacological Interven...</td>\n",
       "      <td>&lt;b&gt;Aim&lt;/b&gt;: Borderline personality disorder (B...</td>\n",
       "      <td>Journal of multidisciplinary healthcare</td>\n",
       "      <td>Maulana, I.; Suryani, S.; Sriati, A.; Yosep, I...</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>4603-4609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDLINE</td>\n",
       "      <td>Ovid Technologies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  MK_IN MK_IN_source  label  ti_ab FH_Err DC_Notes  \\\n",
       "0   0  False         auto  False  False    NaN      NaN   \n",
       "1   1   True         auto   True   True    NaN      NaN   \n",
       "2   2   True         auto   True   True    NaN      NaN   \n",
       "3   3   True         auto  False  False    NaN      NaN   \n",
       "4   4  False         auto  False  False    NaN      NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0  \"Cognitive Assessment in Psychiatric Patients ...   \n",
       "1  \"Comparison of the impact of peer education an...   \n",
       "2  \"Comparison of two Anaesthesia Drugs Thiopenta...   \n",
       "3  \"Efficacy of intensive bilateral Temporo-Parie...   \n",
       "4  \"Empowering Hope: Non-Pharmacological Interven...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Background: Electroconvulsive treatment (ECT) ...   \n",
       "1  Inclusion criteria: \"All patients with psychia...   \n",
       "2  Inclusion criteria: ASA 1 and 2 patients sched...   \n",
       "3  Transcranial magnetic stimulation (TMS) is a n...   \n",
       "4  <b>Aim</b>: Borderline personality disorder (B...   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0        European Journal of Cardiovascular Medicine   \n",
       "1           https://irct.behdasht.gov.ir/trial/80261   \n",
       "2  http://www.ctri.nic.in/Clinicaltrials/pmaindet...   \n",
       "3                        Asian Journal of Psychiatry   \n",
       "4            Journal of multidisciplinary healthcare   \n",
       "\n",
       "                                             authors  Publication_Year  DOI  \\\n",
       "0  Sharma, V.; Gade, V.; Rajeev, A.; Saudam, M.; ...              2023  NaN   \n",
       "1                               IRCT20241108063635N1              2024  NaN   \n",
       "2                                CTRI/2024/09/073405              2024  NaN   \n",
       "3  Tyagi, Priya; Dhyani, Mohan; Khattri, Sumit; T...              2022  NaN   \n",
       "4  Maulana, I.; Suryani, S.; Sriati, A.; Yosep, I...              2024  NaN   \n",
       "\n",
       "  Volume      Pages  Reviewed_Item            DB                 DP  \n",
       "0  13(4)    924-935            NaN        Embase  Ovid Technologies  \n",
       "1    NaN        NaN            NaN          IRCT                NaN  \n",
       "2    NaN        NaN            NaN          CTRI                NaN  \n",
       "3     74        1-7            NaN  APA PsycInfo  Ovid Technologies  \n",
       "4     17  4603-4609            NaN       MEDLINE  Ovid Technologies  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df = pd.read_csv(\"../data/full_dataset.csv\")\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649e514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelized pipeline with prompt caching preservation\n",
    "\n",
    "def process_single_paper(paper_row: pd.Series, questions_df: pd.DataFrame, responses_dir: Path, num_questions=-1):\n",
    "    \"\"\"\n",
    "    Process all questions for a single paper sequentially.\n",
    "    This preserves prompt caching for the paper's title+abstract.\n",
    "\n",
    "    Returns: (paper_id, num_processed, num_skipped)\n",
    "    \"\"\"\n",
    "    paper_id = paper_row[\"id\"]\n",
    "    title = paper_row[\"title\"]\n",
    "    abstract = paper_row[\"abstract\"]\n",
    "\n",
    "    questions_to_process = questions_df.head(num_questions) if num_questions != -1 else questions_df\n",
    "\n",
    "    processed = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for _, question_row in questions_to_process.iterrows():\n",
    "        question_id = question_row[\"id\"]\n",
    "        question_text = question_row[\"question\"]\n",
    "\n",
    "        # skip if already processed\n",
    "        if response_file_exists(paper_id, question_id, responses_dir):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # call LLM with caching\n",
    "            response = call_llm_with_caching(title, abstract, question_text, paper_id, question_id)\n",
    "\n",
    "            if response is None:\n",
    "                continue\n",
    "\n",
    "            # create prompt for saving\n",
    "            prompt = f\"Title: {title}\\n\\nAbstract: {abstract}\\n\\nQuestion: {question_text}\"\n",
    "\n",
    "            # save response\n",
    "            save_response(paper_id=paper_id, question_id=question_id, prompt=prompt, response=response, responses_dir=responses_dir)\n",
    "            processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paper {paper_id}, question {question_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return paper_id, processed, skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e524de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_papers_parallel(papers_df: pd.DataFrame, questions_df: pd.DataFrame, num_papers: int = -1, num_questions: int = -1, max_workers: int = 5):\n",
    "    \"\"\"\n",
    "    Process papers in parallel while keeping questions for each paper sequential.\n",
    "    This maximizes throughput while preserving prompt caching benefits.\n",
    "\n",
    "    Args:\n",
    "        papers_df: DataFrame with papers\n",
    "        questions_df: DataFrame with questions\n",
    "        num_papers: Number of papers to process (-1 = all)\n",
    "        num_questions: Number of questions per paper (-1 = all)\n",
    "        max_workers: Number of parallel workers (papers processed simultaneously)\n",
    "    \"\"\"\n",
    "    papers_to_process = papers_df.head(num_papers) if num_papers != -1 else papers_df\n",
    "\n",
    "    total_papers = len(papers_to_process)\n",
    "    total_questions_per_paper = len(questions_df.head(num_questions) if num_questions != -1 else questions_df)\n",
    "    total_tasks = total_papers * total_questions_per_paper\n",
    "\n",
    "    print(f\"Processing {total_papers} papers x {total_questions_per_paper} questions = {total_tasks} total tasks\")\n",
    "    print(f\"Using {max_workers} parallel workers\\n\")\n",
    "\n",
    "    # thread-safe counter for progress\n",
    "    completed_papers = 0\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # submit all papers for parallel processing\n",
    "        future_to_paper = {\n",
    "            executor.submit(process_single_paper, paper_row, questions_df, responses_dir, num_questions): paper_row[\"id\"]\n",
    "            for _, paper_row in papers_to_process.iterrows()\n",
    "        }\n",
    "\n",
    "        # progress bar for papers\n",
    "        with tqdm(total=total_papers, desc=\"Processing papers\", position=0) as pbar:\n",
    "            for future in as_completed(future_to_paper):\n",
    "                paper_id = future_to_paper[future]\n",
    "                try:\n",
    "                    paper_id, processed, skipped = future.result()\n",
    "                    with lock:\n",
    "                        completed_papers += 1\n",
    "                    pbar.set_postfix({\"paper_id\": paper_id, \"n_processed\": processed, \"n_skipped\": skipped})\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFailed to process paper {paper_id}: {e}\")\n",
    "                    pbar.update(1)\n",
    "\n",
    "    print(f\"Completed processing {completed_papers} papers ({processed + skipped} tasks)\")\n",
    "    print(f\"N. requests to the LLM: {processed}\")\n",
    "    print(f\"N. requests skipped (already processed): {skipped}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c2c5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5747 papers x 29 questions = 166663 total tasks\n",
      "Using 20 parallel workers\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a7a6437ddf458cab44f2e63ffcb20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing papers:   0%|          | 0/5747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing 5747 papers (29 tasks)\n",
      "N. requests to the LLM: 0\n",
      "N. requests skipped (already processed): 29\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "process_papers_parallel(papers_df=papers_df, questions_df=llm_questions, num_papers=-1, num_questions=-1, max_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ebd4f",
   "metadata": {},
   "source": [
    "# Analyze responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responses_to_dataframe(responses_dir) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all JSON response files into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    json_files = list(responses_dir.glob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(\"No response files found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data_records = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            data_records.append(\n",
    "                {\n",
    "                    \"paper_id\": data.get(\"paper_id\"),\n",
    "                    \"question_id\": data.get(\"question_id\"),\n",
    "                    \"response\": data.get(\"response\"),\n",
    "                    \"model\": data.get(\"model\"),\n",
    "                    \"input_tokens\": data.get(\"input_tokens\", 0),\n",
    "                    \"output_tokens\": data.get(\"output_tokens\", 0),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(data_records)\n",
    "\n",
    "    # sort by paper_id and question_id\n",
    "    df = df.sort_values([\"paper_id\", \"question_id\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# cost calculation function (use only input_tokens and output_tokens)\n",
    "def add_cost_column(df, costs_path=\"../src/llm/models_costs.json\", model=OPENAI_MODEL):\n",
    "    with open(costs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        model_costs = json.load(f)\n",
    "\n",
    "    def calculate_cost(row):\n",
    "        input_tokens = row.get(\"input_tokens\")\n",
    "        output_tokens = row.get(\"output_tokens\")\n",
    "\n",
    "        costs = model_costs[model]\n",
    "        input_cost_per_m = float(costs.get(\"COST_PER_1M_TOKENS_INPUT\"))\n",
    "        output_cost_per_m = float(costs.get(\"COST_PER_1M_TOKENS_OUTPUT\"))\n",
    "\n",
    "        input_cost = (input_tokens / 1_000_000) * input_cost_per_m\n",
    "        output_cost = (output_tokens / 1_000_000) * output_cost_per_m\n",
    "\n",
    "        return input_cost + output_cost\n",
    "\n",
    "    df_with_cost = df.copy()\n",
    "    df_with_cost[\"cost_usd\"] = df_with_cost.apply(calculate_cost, axis=1).round(6)\n",
    "    return df_with_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "input_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cost_usd",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "58034521-193b-4c97-b13b-765c9396e1fe",
       "rows": [
        [
         "0",
         "0",
         "E1",
         "NO",
         "gpt-5-mini-2025-08-07",
         "805",
         "10",
         "0.000221"
        ],
        [
         "1",
         "0",
         "E10",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "808",
         "332",
         "0.000866"
        ],
        [
         "2",
         "0",
         "E11",
         "NO",
         "gpt-5-mini-2025-08-07",
         "814",
         "138",
         "0.00048"
        ],
        [
         "3",
         "0",
         "E12",
         "NO",
         "gpt-5-mini-2025-08-07",
         "806",
         "74",
         "0.00035"
        ],
        [
         "4",
         "0",
         "E2",
         "NO",
         "gpt-5-mini-2025-08-07",
         "811",
         "74",
         "0.000351"
        ],
        [
         "5",
         "0",
         "E3",
         "NO",
         "gpt-5-mini-2025-08-07",
         "812",
         "10",
         "0.000223"
        ],
        [
         "6",
         "0",
         "E4",
         "NO",
         "gpt-5-mini-2025-08-07",
         "802",
         "74",
         "0.000348"
        ],
        [
         "7",
         "0",
         "E5",
         "YES",
         "gpt-5-mini-2025-08-07",
         "806",
         "74",
         "0.00035"
        ],
        [
         "8",
         "0",
         "E6",
         "YES",
         "gpt-5-mini-2025-08-07",
         "806",
         "74",
         "0.00035"
        ],
        [
         "9",
         "0",
         "E7",
         "NO",
         "gpt-5-mini-2025-08-07",
         "813",
         "138",
         "0.000479"
        ],
        [
         "10",
         "0",
         "E8",
         "NO",
         "gpt-5-mini-2025-08-07",
         "809",
         "74",
         "0.00035"
        ],
        [
         "11",
         "0",
         "E9",
         "NO",
         "gpt-5-mini-2025-08-07",
         "825",
         "202",
         "0.00061"
        ],
        [
         "12",
         "0",
         "I1",
         "NO",
         "gpt-5-mini-2025-08-07",
         "818",
         "138",
         "0.00048"
        ],
        [
         "13",
         "0",
         "I10",
         "NO",
         "gpt-5-mini-2025-08-07",
         "820",
         "138",
         "0.000481"
        ],
        [
         "14",
         "0",
         "I11",
         "NO",
         "gpt-5-mini-2025-08-07",
         "810",
         "74",
         "0.00035"
        ],
        [
         "15",
         "0",
         "I12",
         "NO",
         "gpt-5-mini-2025-08-07",
         "805",
         "74",
         "0.000349"
        ],
        [
         "16",
         "0",
         "I13",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "811",
         "460",
         "0.001123"
        ],
        [
         "17",
         "0",
         "I14",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "810",
         "332",
         "0.000866"
        ],
        [
         "18",
         "0",
         "I15",
         "NO",
         "gpt-5-mini-2025-08-07",
         "805",
         "74",
         "0.000349"
        ],
        [
         "19",
         "0",
         "I16",
         "NO",
         "gpt-5-mini-2025-08-07",
         "819",
         "74",
         "0.000353"
        ],
        [
         "20",
         "0",
         "I17",
         "NO",
         "gpt-5-mini-2025-08-07",
         "823",
         "202",
         "0.00061"
        ],
        [
         "21",
         "0",
         "I2",
         "NO",
         "gpt-5-mini-2025-08-07",
         "820",
         "74",
         "0.000353"
        ],
        [
         "22",
         "0",
         "I3",
         "YES",
         "gpt-5-mini-2025-08-07",
         "818",
         "138",
         "0.00048"
        ],
        [
         "23",
         "0",
         "I4",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "803",
         "204",
         "0.000609"
        ],
        [
         "24",
         "0",
         "I5",
         "NO",
         "gpt-5-mini-2025-08-07",
         "823",
         "202",
         "0.00061"
        ],
        [
         "25",
         "0",
         "I6",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "803",
         "140",
         "0.000481"
        ],
        [
         "26",
         "0",
         "I7",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "802",
         "140",
         "0.00048"
        ],
        [
         "27",
         "0",
         "I8",
         "NO",
         "gpt-5-mini-2025-08-07",
         "806",
         "202",
         "0.000606"
        ],
        [
         "28",
         "0",
         "I9",
         "UNSURE",
         "gpt-5-mini-2025-08-07",
         "801",
         "204",
         "0.000608"
        ],
        [
         "29",
         "1",
         "E1",
         "NO",
         "gpt-5-mini-2025-08-07",
         "749",
         "74",
         "0.000335"
        ],
        [
         "30",
         "1",
         "E10",
         "NO",
         "gpt-5-mini-2025-08-07",
         "752",
         "74",
         "0.000336"
        ],
        [
         "31",
         "1",
         "E11",
         "NO",
         "gpt-5-mini-2025-08-07",
         "758",
         "202",
         "0.000594"
        ],
        [
         "32",
         "1",
         "E12",
         "NO",
         "gpt-5-mini-2025-08-07",
         "750",
         "74",
         "0.000335"
        ],
        [
         "33",
         "1",
         "E2",
         "NO",
         "gpt-5-mini-2025-08-07",
         "755",
         "74",
         "0.000337"
        ],
        [
         "34",
         "1",
         "E3",
         "NO",
         "gpt-5-mini-2025-08-07",
         "756",
         "10",
         "0.000209"
        ],
        [
         "35",
         "1",
         "E4",
         "NO",
         "gpt-5-mini-2025-08-07",
         "746",
         "74",
         "0.000334"
        ],
        [
         "36",
         "1",
         "E5",
         "NO",
         "gpt-5-mini-2025-08-07",
         "750",
         "74",
         "0.000335"
        ],
        [
         "37",
         "1",
         "E6",
         "NO",
         "gpt-5-mini-2025-08-07",
         "750",
         "74",
         "0.000335"
        ],
        [
         "38",
         "1",
         "E7",
         "NO",
         "gpt-5-mini-2025-08-07",
         "757",
         "74",
         "0.000337"
        ],
        [
         "39",
         "1",
         "E8",
         "NO",
         "gpt-5-mini-2025-08-07",
         "753",
         "74",
         "0.000336"
        ],
        [
         "40",
         "1",
         "E9",
         "NO",
         "gpt-5-mini-2025-08-07",
         "769",
         "74",
         "0.00034"
        ],
        [
         "41",
         "1",
         "I1",
         "YES",
         "gpt-5-mini-2025-08-07",
         "762",
         "394",
         "0.000978"
        ],
        [
         "42",
         "1",
         "I10",
         "NO",
         "gpt-5-mini-2025-08-07",
         "764",
         "202",
         "0.000595"
        ],
        [
         "43",
         "1",
         "I11",
         "NO",
         "gpt-5-mini-2025-08-07",
         "754",
         "74",
         "0.000336"
        ],
        [
         "44",
         "1",
         "I12",
         "NO",
         "gpt-5-mini-2025-08-07",
         "749",
         "138",
         "0.000463"
        ],
        [
         "45",
         "1",
         "I13",
         "YES",
         "gpt-5-mini-2025-08-07",
         "755",
         "138",
         "0.000465"
        ],
        [
         "46",
         "1",
         "I14",
         "YES",
         "gpt-5-mini-2025-08-07",
         "754",
         "458",
         "0.001104"
        ],
        [
         "47",
         "1",
         "I15",
         "NO",
         "gpt-5-mini-2025-08-07",
         "749",
         "138",
         "0.000463"
        ],
        [
         "48",
         "1",
         "I16",
         "YES",
         "gpt-5-mini-2025-08-07",
         "763",
         "586",
         "0.001363"
        ],
        [
         "49",
         "1",
         "I17",
         "YES",
         "gpt-5-mini-2025-08-07",
         "767",
         "138",
         "0.000468"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 166663
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>response</th>\n",
       "      <th>model</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>cost_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>805</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>E10</td>\n",
       "      <td>UNSURE</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>808</td>\n",
       "      <td>332</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>E11</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>814</td>\n",
       "      <td>138</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>E12</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>806</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>E2</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>811</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166658</th>\n",
       "      <td>5746</td>\n",
       "      <td>I5</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>917</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166659</th>\n",
       "      <td>5746</td>\n",
       "      <td>I6</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>897</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166660</th>\n",
       "      <td>5746</td>\n",
       "      <td>I7</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>896</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166661</th>\n",
       "      <td>5746</td>\n",
       "      <td>I8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>900</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166662</th>\n",
       "      <td>5746</td>\n",
       "      <td>I9</td>\n",
       "      <td>NO</td>\n",
       "      <td>gpt-5-mini-2025-08-07</td>\n",
       "      <td>895</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166663 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id question_id response                  model  input_tokens  \\\n",
       "0              0          E1       NO  gpt-5-mini-2025-08-07           805   \n",
       "1              0         E10   UNSURE  gpt-5-mini-2025-08-07           808   \n",
       "2              0         E11       NO  gpt-5-mini-2025-08-07           814   \n",
       "3              0         E12       NO  gpt-5-mini-2025-08-07           806   \n",
       "4              0          E2       NO  gpt-5-mini-2025-08-07           811   \n",
       "...          ...         ...      ...                    ...           ...   \n",
       "166658      5746          I5       NO  gpt-5-mini-2025-08-07           917   \n",
       "166659      5746          I6       NO  gpt-5-mini-2025-08-07           897   \n",
       "166660      5746          I7       NO  gpt-5-mini-2025-08-07           896   \n",
       "166661      5746          I8       NO  gpt-5-mini-2025-08-07           900   \n",
       "166662      5746          I9       NO  gpt-5-mini-2025-08-07           895   \n",
       "\n",
       "        output_tokens  cost_usd  \n",
       "0                  10  0.000221  \n",
       "1                 332  0.000866  \n",
       "2                 138  0.000480  \n",
       "3                  74  0.000350  \n",
       "4                  74  0.000351  \n",
       "...               ...       ...  \n",
       "166658             74  0.000377  \n",
       "166659             10  0.000244  \n",
       "166660             74  0.000372  \n",
       "166661             10  0.000245  \n",
       "166662             74  0.000372  \n",
       "\n",
       "[166663 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load all responses into a DataFrame\n",
    "# responses_df = load_responses_to_dataframe(responses_dir)\n",
    "# responses_df = add_cost_column(responses_df)\n",
    "# responses_df.to_csv(\"../results/5/emanuele/llm_responses.csv\", index=False)\n",
    "# responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee429b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.read_csv(\"../results/5/emanuele/llm_responses.csv\")\n",
    "responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6c9e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_summary(responses_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute cost summary statistics from responses DataFrame.\n",
    "    Returns a DataFrame with total cost, average cost per response,\n",
    "    average cost per paper, and average cost per 1000 papers.\n",
    "    \"\"\"\n",
    "\n",
    "    cost_summary = {\n",
    "        \"total_cost\": responses_df[\"cost_usd\"].sum().round(3),\n",
    "        \"avg_cost_per_response\": responses_df[\"cost_usd\"].mean().round(4),\n",
    "        \"avg_cost_per_paper\": responses_df.groupby(\"paper_id\")[\"cost_usd\"].mean().mean().round(4),\n",
    "        \"avg_cost_per_1000_papers\": (\n",
    "            responses_df.groupby(\"paper_id\")[\"cost_usd\"].mean().sum() / (len(responses_df[\"paper_id\"].unique()) / 1000)\n",
    "        ).round(2),\n",
    "    }\n",
    "    return pd.DataFrame([cost_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "639eeca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_cost_per_response",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_cost_per_paper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_cost_per_1000_papers",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "06968079-bcea-4918-9a1b-bc8b1dcc3b00",
       "rows": [
        [
         "0",
         "54.753",
         "0.0003",
         "0.0003",
         "0.33"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cost</th>\n",
       "      <th>avg_cost_per_response</th>\n",
       "      <th>avg_cost_per_paper</th>\n",
       "      <th>avg_cost_per_1000_papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.753</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_cost  avg_cost_per_response  avg_cost_per_paper  \\\n",
       "0      54.753                 0.0003              0.0003   \n",
       "\n",
       "   avg_cost_per_1000_papers  \n",
       "0                      0.33  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_summary_df = compute_cost_summary(responses_df)\n",
    "cost_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics per paper\n",
    "responses_df.groupby(\"paper_id\").agg(\n",
    "    n_questions=(\"question_id\", \"count\"),\n",
    "    total_cost_usd=(\"cost_usd\", \"sum\"),\n",
    "    avg_cost_usd=(\"cost_usd\", \"mean\"),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to wide format\n",
    "responses_df_wide = responses_df.pivot(index=\"paper_id\", columns=\"question_id\", values=\"response\").reset_index()\n",
    "responses_df_wide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
